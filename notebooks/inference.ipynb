{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iahve/gvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-09 09:20:29,373 - INFO - Device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "main_dir = \"../\"\n",
    "if main_dir not in sys.path:\n",
    "\tsys.path.insert(0, main_dir)\n",
    " \n",
    "import torch\n",
    "\n",
    "from utils import cleanup, seed_everything\n",
    "from network import GPTModel\n",
    "from generation import continue_sentence, Strategies\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = False\n",
    "with_mask_state_dict = torch.load('runs/train_masked/gpt_baseline_with_mask.pth')\n",
    "params = with_mask_state_dict['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = params['vocab_size']\n",
    "embed_dim = params['embed_dim']\n",
    "num_layers = params['num_layers']\n",
    "num_heads = params['num_heads']\n",
    "ff_hidden_dim = params['ff_hidden_dim']\n",
    "\n",
    "masked_model = GPTModel(vocab_size, embed_dim, num_layers, num_heads, ff_hidden_dim, use_causal_mask=masked).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_model.load_state_dict(with_mask_state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy generation:\n",
      "я помню чудное мгновенье, и я не могу................................... \n",
      "\n",
      "Top 5 sampling generation:\n",
      "я помню чудное мгновенье, сердце. а вот тебе теперь есть нечто приятное, змила? сорванья победоносно, и мне легче, я с тобою, ты мои, нам если б от души \n",
      "\n",
      "Beam search generation:\n",
      "я помню чудное мгновенье, - сказал я.................................... \n",
      "\n",
      "Random sample generation:\n",
      "я помню чудное мгновенье, как я умерла, и она теперь ; помнится и поступала, мирные, что все какие - то дальнеи губ. я должен уити.. а. я тебе,\n"
     ]
    }
   ],
   "source": [
    "cleanup()\n",
    "seed_everything(1337)\n",
    "print('Greedy generation:')\n",
    "greedy_sentence = continue_sentence(\"Я помню чудное мгновенье\", masked_model, max_len=45, strategy=Strategies.greedy)\n",
    "print(greedy_sentence, '\\n')\n",
    "\n",
    "print('Top k sampling generation:')\n",
    "\n",
    "strategy_top_k = Strategies.top_k\n",
    "strategy_top_k.param = 500\n",
    "top_k_sentence = continue_sentence(\"Я помню чудное мгновенье\", masked_model, max_len=45, strategy=strategy_top_k)\n",
    "print(top_k_sentence, '\\n')\n",
    "\n",
    "print('Beam search generation:')\n",
    "beam_sentence = continue_sentence(\"Я помню чудное мгновенье,\", masked_model, max_len=45, strategy=Strategies.beam)\n",
    "print(beam_sentence, '\\n')\n",
    "\n",
    "print('Random sample generation:')\n",
    "random_sample_sentence = continue_sentence(\"Я помню чудное мгновенье,\", masked_model, max_len=45, strategy=Strategies.random_sample)\n",
    "print(random_sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мои дядя самых честных правил, - я должен был его любишь изъяснить. вот ты не то что на моем воспоминание, где жизнь, нет, и я сам был сам, как в уме моем кель\n",
      "четыре года потратил деонардо на меня, на меня не пролишь ; а он вам отвечал. я не люблю, потому что будет угодно! я не могу, что еи ни один только что мог бы\n",
      "если сила плохих людеи в том, что они вместе, то хорошим людям, чтобы стать силои, надо. ну, сам, я им теперь говорю ; я верю!. все эти товары\n"
     ]
    }
   ],
   "source": [
    "strategy_top_k = Strategies.top_k\n",
    "strategy_top_k.param = 100\n",
    "print(continue_sentence(\"Мой дядя самых честных правил,\", masked_model, max_len=45, strategy=strategy_top_k))\n",
    "print(continue_sentence(\"Четыре года потратил Деонардо на\", masked_model, max_len=45, strategy=strategy_top_k))\n",
    "print(continue_sentence(\"Если сила плохих людей в том, что они вместе, то хорошим людям, чтобы стать силой, надо\", masked_model, max_len=45, strategy=strategy_top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = True\n",
    "without_mask_state_dict = torch.load('runs/train_masked/gpt_baseline_without_mask.pth')\n",
    "params = without_mask_state_dict['hyperparameters']\n",
    "\n",
    "vocab_size = params['vocab_size']\n",
    "embed_dim = params['embed_dim']\n",
    "num_layers = params['num_layers']\n",
    "num_heads = params['num_heads']\n",
    "ff_hidden_dim = params['ff_hidden_dim']\n",
    "\n",
    "maskless_model = GPTModel(vocab_size, embed_dim, num_layers, num_heads, ff_hidden_dim, use_causal_mask=masked).to(device)\n",
    "\n",
    "maskless_model.load_state_dict(without_mask_state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мои дядя самых честных правил, а не совсем даже никто другои и не был убежден. \" умнистныи, когда - то никогда, а по нашему, что на первому не скажет, что человек\n",
      "четыре года потратил деонардо на скашечныи чашу. - - - еи стансеи не выпуск в своеи, а в тоскную, которая может ехать, как бы в\n",
      "если сила плохих людеи в том, что они вместе, то хорошим людям, чтобы стать силои, надо, помогать в них, а в то есть ; иначе быть может, и сами собес\n"
     ]
    }
   ],
   "source": [
    "strategy_top_k = Strategies.top_k\n",
    "strategy_top_k.param = 100\n",
    "print(continue_sentence(\"Мой дядя самых честных правил,\", maskless_model, max_len=45, strategy=strategy_top_k))\n",
    "print(continue_sentence(\"Четыре года потратил Деонардо на\", maskless_model, max_len=45, strategy=strategy_top_k))\n",
    "print(continue_sentence(\"Если сила плохих людей в том, что они вместе, то хорошим людям, чтобы стать силой, надо\", masked_model, max_len=45, strategy=strategy_top_k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
